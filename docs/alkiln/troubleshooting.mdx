---
id: alkiln_troubleshooting
title: ALKiln troubleshooting and errors
sidebar_label: WIP Troubleshooting & errors
slug: /alkiln/trouble
---

import { GTOYS, AutoDIY, KittyLitter } from './components/\_test_types.js';

:::warning
WIP (Work in progress)
:::

This page will try to help you figure out what is going wrong when you have errors, warnings, or other problems with your ALKiln tests.

This page helps with:

- Common mistakes
- Errors from the third-party libraries that ALKiln uses
<!-- - ALKiln errors and error and warning codes -->

<!-- This document is still under development and contains only some of the possible errors. Every ALKiln error and warning should have a code, though, and giving us that code can help us narrow down your problem. -->

<!--
## Failing tests {#failure}

Check report
Check screenshots/pics
Check HTML
Check bottom of test output (for cucumber info)
Go through the interview manually. Make sure to pull in a fresh new Project.
 -->

<!--
## The variable could not be looked up

> There was a reference to a variable ‘some_var’ that could not be looked up in the question file (for language ‘en’) or in any of the files incorporated by reference into the question file.
 -->

## Everything works fine when I run the test manually {#manual-works}

Or "It works when I run the interview manually" or "The tests pass when I run them with ALKilnInThePlayground".

### Undefined step {#step-undefined}

**Symptom:**

At the very bottom of your [console output](writing_tests.mdx#console) you see the message "Undefined" and "You can implement missing steps with the snippets below".

**Problem:**

You have a typo in the Step that failed. The error message should contain the text of the Step.

**Solution:**

1. Check the documentation for the Step again.
1. Copy/paste the Step from the documentation, then copy/paste just the parts you need to customize.
1. To double-check that there is a difference between the old version of the Step and the new one, use a diff checker like [https://www.diffchecker.com/text-compare/](https://www.diffchecker.com/text-compare/).
1. If the diff checker shows that the text is the same, contact us. Maybe we have a typo in our documentation.
1. If the text is different, try the test again.
1. If the test has the same problem, contact us. Maybe we have a typo in our documentation.


### Error: File not found {#file-not-found}

<!-- Find that error -->

This might mean that you have a file in your Playground Project, but that you still have to save it on the Project's Packages page and commit that to GitHub. Your tests will pass for that Project in your Playground, but your interview will break when you or others install it from GitHub.

### Error: Variable could not be looked up {#variable-not-found}

**Symptom:**

On the error screenshot of the page, you see the error message you see this error:

> There was a reference to a variable ‘some_var’ that could not be looked up in the question file (for language ‘en’) or in any of the files incorporated by reference into the question file.

**Problem:**

This is a reference error. It means docassemble tried to get the definition for a variable, but couldn't find the variable anywhere in your code or in the code you included or imported.

Sometime the easiest way to see what is wrong is to run the interview manually. Fill in the same values as the test fills in. You can then see what goes wrong when you reach the error.

If running the test manually seems to work fine, but running the automated tests gets a reference error, the test probably either has an incorrect variable name or an incorrect value for a variable. It might even be a value from a page much farther back than you expect.

If you have a typo, ALKiln will be unable to find the variable or value that you were trying to set. In some Steps, that will cause a test to fail immediately. In a [Story Table Step](#story-table), ALKiln will just skip optional fields.

[Checkboxes](#checkboxes) are a common place where authors make mistakes.

**Solution:**

Check for:

- [Incorrectly setting checkbox values](writing_tests.mdx#checkboxes)
- Typos in variable names
- Typos in the value for radio button options or similar fields

You can check for incorrect variable or value names in a few different ways.

1. If you give every question in your interview an id, the report can help show you where the test failed or where ALKiln skipped setting variables. For each test, the report often has a list of question ids. For each question id, the report has a list of variables that ALKiln set on the page. If the test failed, you can see what question id the test got to. You can also check previous questions to see what variables are missing from each of those pages - what fields ALKiln skipped.
1. It is more annoying, but in most cases[^except] you can copy the variable name from your test and search for it in your interview code. You can do the same for values of multiple choice questions.
1. Alternatively, in most cases[^except] you can go through the interview manually. For every single page  (even if you think this page has nothing to do with the problem), click on the `<\/>` in the nav bar to see the source of the page. Copy the name of the variable from your test and search for it on the page of the running interview. For multiple choice questions, do the same for the value. Then answer the questions _exactly_ as the test would answer them.
1. If you are unable to find the name of the variable or value in any other way, our last suggestion is the hardest to do, but most reliable - run the interview manually and examine each page's HTML to find exact names. This is complex and we are happy to show you how to do this. Here is a refresher:
    1. Go to a new page.
    1. Click on the `<\/>` in the nav bar to see the source of the page.
    1. For every field in the page:
        1. If you cannot see the variable name or value, like for an `object_checkbox` field or a field created with `code`:
            1. Open the browser development tools.
            1. Examine the DOM of a field to find the encoded name of the variable.
            1. Use `atob('the encoded name or id')` with the encoded name or id to fully decode every part of the variable name. You may have to decode multiple times.
            1. From those decoded values, put together the variable name that you need to use. <!-- Something about nested double quotes and single quotes? -->
        1. Copy the variable name and use your editor to search for that exact variable name in your test file. The variable name is the fully decoded and reconstructed variable name.
        1. In the final variable name, replace `x`, `i`, `j`, etc. with their actual values on that page.
        1. If the field is a multiple choice field like radio buttons, do the same for the value and use your editor to search for that exact value in your test file. Make sure it appears along with the correct variable name. For a checkbox field, the value is either `True` or `False`.
        1. Set the value exactly as the test would have set it.
    1. Go on to the next page till you reach the end of your interview or the error.

<!-- Check new notes for getting decoding values and see if there are easier instructions for getting HTML values -->


[^except]: In some cases, you will be unable to find a variable or value name in your interview code. For example, `object`-type fields, like `object_multiselect` or for fields that use `code` might use values that are outside of your interview code. They might be in a module of your interview, in a module of an interview you `include`, in a database like S3, or somewhere else.


## Skipped variables {#skipped}

If you look in a test report and see that ALKiln skipped setting a variable, you probably have a typo. See the [error for a missing variable reference](#variable-not-found)

<!--
## Not setting variables

`mandatory: True` questions
 -->

<!--
 ## Infinite loop {#infinite-loop}

WIP

Same var or vars set over and over again and never stop.

A page that has no invalidation message and yet is unable to move on.
 -->

<!--
## Timing out

1. Could need more time for Steps to run, pages to load, documents to upload or download, etc. Increase the time you give those to happen by using the ["max seconds"](writing_tests.mdx#custom-timeout) Step.
1. Server reloading
1. Something went wrong with the library ALKiln is using and it got disconnected somehow.
 -->

<!--
## Tests are taking too long

Tests that fail take at least twice as long as tests that succeed because ALKiln repeats tests that failed. That's because some failures are caused by a server reload and ALKiln wants to give those type of failures an opportunity to try again. Unfortunately, ALKiln can't retry conditionally yet.

TODO: Look into this. I don't think this is the reason. ALKiln Story Table would try to continue and get an "invalid answer" feedback and should be able to tell that it is an actual failure. Is this problem from something else?:
Tests that end up on the wrong page take a default amount of 30 seconds to fail. Then those test are re-run, so they take at least 1 minute each. That's because there is no way for ALKiln to know whether the server is just taking a long time to load the correct page or if the test really ended up on the wrong page. This is especially a problem for the ALKiln Story Table (I think?).
 -->

<!--
## Inconsistent failures {#inconsistent}

If a test sometimes fails because it says it couldn't find a field or element on the page, and other times it passes, this Step can help. Use "wait" to pause for a moment before trying to interact. This is usually because some elements can take different amounts of time to fully load.

Not all collapsed elements are being expanded - wait for each element to be expanded. When elements are moving on the page ALKiln has trouble interacting with them. Also, if it's helpful, you can instead use code to start with expanded elements when tests are running/when you are debugging. Or you can also go from bottom to top. When you go from top to bottom, elements below move around making it hard for ALKiln to interact. When you expand ones at the bottom first, the ones above stay in the same place.
-->

<!--
## Some file names have the word null in them

Maybe "Some JSON files aren't being saved with the "save variables" (writing#save-vars) or "compare json" (writing#compare-json) Steps" - check on JSON file names to make sure they have a timestamp

Make sure every question block you create has an id
 -->

## Phrase is missing {#missing-phrase}

<!-- TODO: when there are error codes: Error code ALK0?? -->

WIP

Example error:

```txt
The text "a document called a 'Certified docket sheet'" SHOULD be on this page, but it's NOT
```

### Typo

WIP

1. Regular typo

### Quotes and other catastrophes {#da-converted-text}

WIP

**Problem**

Even though the text might look correct, you might not have used exactly characters the user is seeing. Docassemble sometimes shows the user slightly different characters than the ones you typed in your code.

**Solution**

Run the interview[^faster] until the page that has the text. Use your cursor to select the text you want to test. Copy and paste that text into your test.

**What is going on?**

When you tell the test to look for a phrase on a page, you have to give it the exact characters that are on the page the user sees. That is, ignore the text that you wrote in your code.

See a section in [tips about quotes](writing_tests.mdx#special-chars) for more detailed information. To sum up, it is best to copy/paste the text **straight from the screen the user sees**.

:::danger Wrong
```gherkin
  I should see the phrase "a document called a 'Certified docket sheet'"
```
:::

:::tip Right
```gherkin
  I should see the phrase "a document called a ‘Certified docket sheet’"
```
:::


[^faster]: To speed things up, you might instead be able to use the HTML page that the report created for you. It is in the folder with the name of the Scenario for that test.


<!-- ## There are no artifacts, files, or folders

The tests completely failed to run. For this, it is especially important to look at the console output and error messages. In GitHub, those might be above where the tests even run.

There might be a typo in a test (link). For <KittyLitter> tests, the docker container might not have started up correctly. Maybe your server was down. Maybe the API key you gave ALKiln was wrong or got deleted with a server restart. That might be because of your own errors or because of GitHub.

Also, other services like GitHub or node package manager (npm) might have been having various kinds of trouble.
-->


## Timeout or "it took too long to load the next page" error {#next-page-timeout}

Different problems can cause the report to say that something "took too long" or caused a "timeout" error.

A "timeout" error can happen when a page took too long to load at some point in setup, when running tests, or during test cleanup. This can be because:

1. The page was trying to load a big file.
1. ALKiln could not continue to the next page for some reason.
1. A Story Table was unable to reach the page with the specified `id`.
1. There's a typo in the name of the interview YAML file that the test should go to.

If a page was taking too long to load a big file, use [the `max seconds` Step](writing_tests.mdx#custom-timeout) to give the page more time to load.

You might be able to look at the error page picture for more details. In GitHub, you can download the test artifacts <!-- TODO: Add link to section on GitHub artifacts --> to look for it.

In GitHub, this error can also happen when:

1. The server was busy for too long.
1. The server was down.
1. That url is stored in the `SERVER_URL` [GitHub secret](https://docs.github.com/en/actions/security-guides/encrypted-secrets) is wrong or out of date.

If the server might have been busy or down, try [re-running the tests](https://docs.github.com/en/actions/managing-workflow-runs/re-running-workflows-and-jobs#re-running-all-the-jobs-in-a-workflow).

You won't be able to tell if the `SERVER_URL` is wrong - GitHub considers the value of the secret to be sensitive information, so it's impossible to see that value. You can still give it a new value, though, and that's worth trying. Find the address of the docassemble server where the docassemble testing account is located. Edit the secret to give it that url.

## Invalid playground path error

If you see the text "invalid playground path" in the report, that means the `Given I start the interview at...` Step for that scenario is naming an interview that doesn't exist. Check for a typo.

## UnhandledPromiseRejection error

This is a misleading error. You need to read the text of the whole paragraph to see what the actual error is.

## Inconsistent cell count error

This error prevents all of your tests being run. The message is telling you that something about the syntax of the table is wrong. One of your story tables could missing a pipe (`|`) or could have an extra pipe, etc.

To fix this you can find the syntax typos by using an editor like the [editor at AssertThat](https://www.assertthat.com/online-gherkin-editor). It will let you paste in your test code and will show a red 'x' next to the lines that have syntax errors. The editor will not show error next to lines that are commented out. Those are the ones that start with `#`.

The error message will include text similar to this:

```bash
Error: Parse error in 'docassemble/ChildSupport/data/sources/new_case.feature': (10:5): inconsistent cell count within the table
```

<!-- ### Access Denied -->

<!--
    required file was missing
    ALKiln was unable to continue to the next page,
    missing phrase
-->

<!-- writing_tests.mdx#errors, writing_tests.mdx#reports -->
