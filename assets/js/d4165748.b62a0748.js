"use strict";(self.webpackChunkdocassemble_assembly_line_documentation=self.webpackChunkdocassemble_assembly_line_documentation||[]).push([[7210],{8453:(e,s,n)=>{n.d(s,{R:()=>o,x:()=>r});var i=n(6540);const t={},l=i.createContext(t);function o(e){const s=i.useContext(l);return i.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function r(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),i.createElement(l.Provider,{value:s},e.children)}},8558:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>d,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>a});const i=JSON.parse('{"id":"components/ALToolbox/llms","title":"ALToolbox.llms","description":"* ALToolbox.llms","source":"@site/docs/components/ALToolbox/llms.md","sourceDirName":"components/ALToolbox","slug":"/components/ALToolbox/llms","permalink":"/docs/components/ALToolbox/llms","draft":false,"unlisted":false,"editUrl":"https://github.com/SuffolkLITLab/docassemble-AssemblyLine-documentation/edit/main/docs/components/ALToolbox/llms.md","tags":[],"version":"current","frontMatter":{},"sidebar":"docs","previous":{"title":"ALToolbox.save_input_data","permalink":"/docs/components/ALToolbox/save_input_data"},"next":{"title":"Customizing look and feel","permalink":"/docs/components/ALThemeTemplate/overview"}}');var t=n(4848),l=n(8453);const o={},r="ALToolbox.llms",d={},a=[{value:"chat_completion",id:"chat_completion",level:3},{value:"Arguments",id:"arguments",level:4},{value:"Returns",id:"returns",level:4},{value:"extract_fields_from_text",id:"extract_fields_from_text",level:3},{value:"Arguments",id:"arguments-1",level:4},{value:"Returns",id:"returns-1",level:4},{value:"extract_fields_from_file",id:"extract_fields_from_file",level:3},{value:"Arguments",id:"arguments-2",level:4},{value:"Returns",id:"returns-2",level:4},{value:"match_goals_from_text",id:"match_goals_from_text",level:3},{value:"Arguments",id:"arguments-3",level:4},{value:"Returns",id:"returns-3",level:4},{value:"classify_text",id:"classify_text",level:3},{value:"Arguments",id:"arguments-4",level:4},{value:"Returns",id:"returns-4",level:4},{value:"synthesize_user_responses",id:"synthesize_user_responses",level:3},{value:"Arguments",id:"arguments-5",level:4},{value:"Returns",id:"returns-5",level:4},{value:"define_fields_from_dict",id:"define_fields_from_dict",level:3},{value:"Arguments",id:"arguments-6",level:4},{value:"Goal Objects",id:"goal-objects",level:2},{value:"Attributes",id:"attributes",level:4},{value:"response_satisfies_me_or_follow_up",id:"response_satisfies_me_or_follow_up",level:3},{value:"Arguments",id:"arguments-7",level:4},{value:"Returns",id:"returns-6",level:4},{value:"get_next_question",id:"get_next_question",level:3},{value:"Arguments",id:"arguments-8",level:4},{value:"Returns",id:"returns-7",level:4},{value:"GoalDict Objects",id:"goaldict-objects",level:2},{value:"satisfied",id:"satisfied",level:3},{value:"Returns",id:"returns-8",level:4},{value:"GoalQuestion Objects",id:"goalquestion-objects",level:2},{value:"Attributes",id:"attributes-1",level:4},{value:"complete",id:"complete",level:3},{value:"GoalSatisfactionList Objects",id:"goalsatisfactionlist-objects",level:2},{value:"Attributes",id:"attributes-2",level:4},{value:"mark_satisfied_goals",id:"mark_satisfied_goals",level:3},{value:"keep_going",id:"keep_going",level:3},{value:"Returns",id:"returns-9",level:4},{value:"need_more_questions",id:"need_more_questions",level:3},{value:"Returns",id:"returns-10",level:4},{value:"satisfied",id:"satisfied-1",level:3},{value:"Returns",id:"returns-11",level:4},{value:"get_next_goal_and_question",id:"get_next_goal_and_question",level:3},{value:"Returns",id:"returns-12",level:4},{value:"synthesize_draft_response",id:"synthesize_draft_response",level:3},{value:"Returns",id:"returns-13",level:4},{value:"provide_feedback",id:"provide_feedback",level:3},{value:"Arguments",id:"arguments-9",level:4},{value:"Returns",id:"returns-14",level:4},{value:"GoalOrientedQuestion Objects",id:"goalorientedquestion-objects",level:2},{value:"Attributes",id:"attributes-3",level:4},{value:"complete",id:"complete-1",level:3},{value:"response_as_text",id:"response_as_text",level:3},{value:"Returns",id:"returns-15",level:4},{value:"build_field_list",id:"build_field_list",level:3},{value:"Returns",id:"returns-16",level:4},{value:"GoalOrientedQuestionList Objects",id:"goalorientedquestionlist-objects",level:2},{value:"Attributes",id:"attributes-4",level:4},{value:"generate_initial_question_fields",id:"generate_initial_question_fields",level:3},{value:"Returns",id:"returns-17",level:4},{value:"build_initial_field_list",id:"build_initial_field_list",level:3},{value:"Returns",id:"returns-18",level:4},{value:"initial_response_as_text",id:"initial_response_as_text",level:3},{value:"Returns",id:"returns-19",level:4},{value:"keep_going",id:"keep_going-1",level:3},{value:"Returns",id:"returns-20",level:4},{value:"need_more_questions",id:"need_more_questions-1",level:3},{value:"Returns",id:"returns-21",level:4},{value:"satisfied",id:"satisfied-2",level:3},{value:"Returns",id:"returns-22",level:4},{value:"get_next_question",id:"get_next_question-1",level:3},{value:"Returns",id:"returns-23",level:4},{value:"synthesize_draft_response",id:"synthesize_draft_response-1",level:3},{value:"Returns",id:"returns-24",level:4},{value:"provide_feedback",id:"provide_feedback-1",level:3},{value:"Arguments",id:"arguments-10",level:4},{value:"Returns",id:"returns-25",level:4},{value:"IntakeQuestion Objects",id:"intakequestion-objects",level:2},{value:"Attributes",id:"attributes-5",level:4},{value:"complete",id:"complete-2",level:3},{value:"IntakeQuestionList Objects",id:"intakequestionlist-objects",level:2},{value:"Attributes",id:"attributes-6",level:4},{value:"need_more_questions",id:"need_more_questions-2",level:3},{value:"Returns",id:"returns-26",level:4}];function c(e){const s={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,l.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.header,{children:(0,t.jsx)(s.h1,{id:"altoolboxllms",children:"ALToolbox.llms"})}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.a,{href:"#ALToolbox.llms",children:"ALToolbox.llms"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.chat_completion",children:"chat_completion"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.extract_fields_from_text",children:"extract_fields_from_text"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.extract_fields_from_file",children:"extract_fields_from_file"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.match_goals_from_text",children:"match_goals_from_text"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.classify_text",children:"classify_text"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.synthesize_user_responses",children:"synthesize_user_responses"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.define_fields_from_dict",children:"define_fields_from_dict"})}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.a,{href:"#ALToolbox.llms.Goal",children:"Goal"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.Goal.response_satisfies_me_or_follow_up",children:"response_satisfies_me_or_follow_up"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.Goal.get_next_question",children:"get_next_question"})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalDict",children:"GoalDict"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalDict.satisfied",children:"satisfied"})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalQuestion",children:"GoalQuestion"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalQuestion.complete",children:"complete"})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalSatisfactionList",children:"GoalSatisfactionList"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalSatisfactionList.mark_satisfied_goals",children:"mark_satisfied_goals"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalSatisfactionList.keep_going",children:"keep_going"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalSatisfactionList.need_more_questions",children:"need_more_questions"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalSatisfactionList.satisfied",children:"satisfied"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalSatisfactionList.get_next_goal_and_question",children:"get_next_goal_and_question"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalSatisfactionList.synthesize_draft_response",children:"synthesize_draft_response"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalSatisfactionList.provide_feedback",children:"provide_feedback"})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalOrientedQuestion",children:"GoalOrientedQuestion"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalOrientedQuestion.complete",children:"complete"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalOrientedQuestion.response_as_text",children:"response_as_text"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalOrientedQuestion.build_field_list",children:"build_field_list"})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalOrientedQuestionList",children:"GoalOrientedQuestionList"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalOrientedQuestionList.generate_initial_question_fields",children:"generate_initial_question_fields"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalOrientedQuestionList.build_initial_field_list",children:"build_initial_field_list"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalOrientedQuestionList.initial_response_as_text",children:"initial_response_as_text"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalOrientedQuestionList.keep_going",children:"keep_going"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalOrientedQuestionList.need_more_questions",children:"need_more_questions"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalOrientedQuestionList.satisfied",children:"satisfied"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalOrientedQuestionList.get_next_question",children:"get_next_question"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalOrientedQuestionList.synthesize_draft_response",children:"synthesize_draft_response"})}),"\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.GoalOrientedQuestionList.provide_feedback",children:"provide_feedback"})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.a,{href:"#ALToolbox.llms.IntakeQuestion",children:"IntakeQuestion"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.IntakeQuestion.complete",children:"complete"})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.a,{href:"#ALToolbox.llms.IntakeQuestionList",children:"IntakeQuestionList"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:(0,t.jsx)(s.a,{href:"#ALToolbox.llms.IntakeQuestionList.need_more_questions",children:"need_more_questions"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.chat_completion"}),"\n",(0,t.jsx)(s.h3,{id:"chat_completion",children:"chat_completion"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'def chat_completion(\n    system_message: Optional[str] = None,\n    user_message: Optional[str] = None,\n    openai_client: Optional[OpenAI] = None,\n    openai_api: Optional[str] = None,\n    temperature: float = 0.5,\n    json_mode=False,\n    model: str = "gpt-4o",\n    messages: Optional[List[Dict[str, str]]] = None,\n    skip_moderation: bool = True,\n    openai_base_url: Optional[str] = None,\n    max_output_tokens: Optional[int] = None,\n    max_input_tokens: Optional[int] = None,\n    reasoning_effort: Optional[Literal["minimal", "low", "medium",\n                                       "high"]] = None\n) -> Union[List[Any], Dict[str, Any], str]\n'})}),"\n",(0,t.jsx)(s.p,{children:"A light wrapper on the OpenAI chat endpoint."}),"\n",(0,t.jsx)(s.p,{children:"Includes support for token limits, minimal error handling, and moderation."}),"\n",(0,t.jsx)(s.h4,{id:"arguments",children:"Arguments"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"system_message"})," ",(0,t.jsx)(s.em,{children:"str"})," - The role the chat engine should play"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"user_message"})," ",(0,t.jsx)(s.em,{children:"str"})," - The message (data) from the user"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"openai_client"})," ",(0,t.jsx)(s.em,{children:"Optional[OpenAI]"})," - An OpenAI client object, optional. If omitted, will fall back to creating a new OpenAI client with the API key provided as an environment variable"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"openai_api"})," ",(0,t.jsx)(s.em,{children:"Optional[str]"})," - the API key for an OpenAI client, optional. If provided, a new OpenAI client will be created."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"temperature"})," ",(0,t.jsx)(s.em,{children:"float"})," - The temperature to use for the GPT API"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"json_mode"})," ",(0,t.jsx)(s.em,{children:"bool"})," - Whether to use JSON mode for the GPT API. Requires the word ",(0,t.jsx)(s.code,{children:"json"})," in the system message, but will add if you omit it."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"model"})," ",(0,t.jsx)(s.em,{children:"str"})," - The model to use for the GPT API"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"messages"})," ",(0,t.jsx)(s.em,{children:"Optional[List[Dict[str, str]]]"})," - A list of messages to send to the chat engine. If provided, system_message and user_message will be ignored."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"skip_moderation"})," ",(0,t.jsx)(s.em,{children:"bool"})," - Whether to skip the OpenAI moderation step, which may save seconds but risks banning your account. Only enable when you have full control over the inputs."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"openai_base_url"})," ",(0,t.jsx)(s.em,{children:"Optional[str]"}),' - The base URL for the OpenAI API. Defaults to value provided in the configuration or "',(0,t.jsx)(s.a,{href:"https://api.openai.com/v1/",children:"https://api.openai.com/v1/"}),'".']}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"max_output_tokens"})," ",(0,t.jsx)(s.em,{children:"Optional[int]"})," - The maximum number of tokens to return from the API. Defaults to 16380."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"max_input_tokens"})," ",(0,t.jsx)(s.em,{children:"Optional[int]"}),' - The maximum number of tokens to send to the API. Defaults to 128000.\nreasoning_effort (Optional[Literal["minimal", "low", "medium", "high"]]) = None: The reasoning effort to use for thinking models. Defaults to value provided in the configuration or "low".']}),"\n"]}),"\n",(0,t.jsx)(s.h4,{id:"returns",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"A string with the response from the API endpoint or JSON data if json_mode is True"}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.extract_fields_from_text"}),"\n",(0,t.jsx)(s.h3,{id:"extract_fields_from_text",children:"extract_fields_from_text"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'def extract_fields_from_text(\n    text: str,\n    field_list: Dict[str, str],\n    openai_client: Optional[OpenAI] = None,\n    openai_api: Optional[str] = None,\n    temperature: float = 0,\n    model="gpt-5-nano",\n    reasoning_effort: Optional[Literal["minimal", "low", "medium",\n                                       "high"]] = "low"\n) -> Dict[str, Any]\n'})}),"\n",(0,t.jsx)(s.p,{children:"Extracts fields from text."}),"\n",(0,t.jsx)(s.h4,{id:"arguments-1",children:"Arguments"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"text"})," ",(0,t.jsx)(s.em,{children:"str"})," - The text to extract fields from"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"field_list"})," ",(0,t.jsx)(s.em,{children:"Dict[str, str]"})," - A list of fields to extract, with the key being the field name and the value being a description of the field"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"openai_client"})," ",(0,t.jsx)(s.em,{children:"Optional[OpenAI]"})," - An OpenAI client object. Defaults to None."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"openai_api"})," ",(0,t.jsx)(s.em,{children:"Optional[str]"})," - An OpenAI API key. Defaults to None."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"temperature"})," ",(0,t.jsx)(s.em,{children:"float"})," - The temperature to use for the OpenAI API. Defaults to 0."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"model"})," ",(0,t.jsx)(s.em,{children:"str"}),' - The model to use for the OpenAI API. Defaults to "gpt-5-nano".']}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"reasoning_effort"})," ",(0,t.jsx)(s.em,{children:'Optional[Literal["minimal", "low", "medium", "high"]]'}),' - The reasoning effort to use for the LLM. Defaults to "low".']}),"\n"]}),"\n",(0,t.jsx)(s.h4,{id:"returns-1",children:"Returns"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"dict"})," - A dictionary of fields extracted from the text"]}),"\n"]}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.extract_fields_from_file"}),"\n",(0,t.jsx)(s.h3,{id:"extract_fields_from_file",children:"extract_fields_from_file"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'def extract_fields_from_file(\n        the_file: Union[DAFile, DAFileList],\n        field_list: Dict[str, str],\n        openai_client: Optional[OpenAI] = None,\n        openai_api: Optional[str] = None,\n        model: str = "gpt-5-nano",\n        reasoning_effort: Optional[Literal["minimal", "low", "medium",\n                                           "high"]] = "low",\n        process_pdfs_with_ai: bool = True) -> Dict[str, Any]\n'})}),"\n",(0,t.jsx)(s.p,{children:"Extracts data (in the form of a list of expected fields) from a file using an LLM."}),"\n",(0,t.jsx)(s.p,{children:"When the file is a PDF, relies on the OpenAI vision API to interpret the document.\nNote that this may increase cost, but will also improve accuracy."}),"\n",(0,t.jsx)(s.p,{children:"If it is another file type that is convertible by Markitdown, it uses Markitdown to\nconvert the file to text first."}),"\n",(0,t.jsx)(s.p,{children:"Can be combined with define_fields_from_dict to populate Docassemble fields."}),"\n",(0,t.jsx)(s.h4,{id:"arguments-2",children:"Arguments"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"the_file"})," ",(0,t.jsx)(s.em,{children:"Union[DAFile, DAFileList]"})," - The file to extract fields from"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"field_list"})," ",(0,t.jsx)(s.em,{children:"Dict[str, str]"})," - A list of fields to extract, with the key being the field name and the value being a description of the field"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"openai_client"})," ",(0,t.jsx)(s.em,{children:"Optional[OpenAI]"})," - An OpenAI client object. Defaults to None."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"openai_api"})," ",(0,t.jsx)(s.em,{children:"Optional[str]"})," - An OpenAI API key. Defaults to None."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"model"})," ",(0,t.jsx)(s.em,{children:"str"}),' - The model to use for the OpenAI API. Defaults to "gpt-5-nano".']}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"reasoning_effort"})," ",(0,t.jsx)(s.em,{children:'Optional[Literal["minimal", "low", "medium", "high"]]'}),' - The reasoning effort to use for the LLM. Defaults to "low".']}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"process_pdfs_with_ai"})," ",(0,t.jsx)(s.em,{children:"bool"})," - Whether to process PDFs with the OpenAI API (True) or convert to text first (False). Defaults to True."]}),"\n"]}),"\n",(0,t.jsx)(s.h4,{id:"returns-2",children:"Returns"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"dict"})," - A dictionary of fields extracted from the file"]}),"\n"]}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.match_goals_from_text"}),"\n",(0,t.jsx)(s.h3,{id:"match_goals_from_text",children:"match_goals_from_text"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'def match_goals_from_text(question: str,\n                          user_response: str,\n                          goals: Dict[str, str],\n                          openai_client: Optional[OpenAI] = None,\n                          openai_api: Optional[str] = None,\n                          temperature: float = 0,\n                          model="gpt-4o-mini") -> Dict[str, Any]\n'})}),"\n",(0,t.jsx)(s.p,{children:"Reads a user's message and determines whether it meets a set of goals, with the help of an LLM."}),"\n",(0,t.jsx)(s.h4,{id:"arguments-3",children:"Arguments"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"question"})," ",(0,t.jsx)(s.em,{children:"str"})," - The question that was asked to the user"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"user_response"})," ",(0,t.jsx)(s.em,{children:"str"})," - The user's response to the question"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"goals"})," ",(0,t.jsx)(s.em,{children:"Dict[str,str]"})," - A list of goals to extract, with the key being the goal name and the value being a description of the goal"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"openai_client"})," ",(0,t.jsx)(s.em,{children:"Optional[OpenAI]"})," - An OpenAI client object. Defaults to None."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"openai_api"})," ",(0,t.jsx)(s.em,{children:"Optional[str]"})," - An OpenAI API key. Defaults to None."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"temperature"})," ",(0,t.jsx)(s.em,{children:"float"})," - The temperature to use for the OpenAI API. Defaults to 0."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"model"})," ",(0,t.jsx)(s.em,{children:"str"}),' - The model to use for the OpenAI API. Defaults to "gpt-4o-mini".']}),"\n"]}),"\n",(0,t.jsx)(s.h4,{id:"returns-3",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"A dictionary of fields extracted from the text"}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.classify_text"}),"\n",(0,t.jsx)(s.h3,{id:"classify_text",children:"classify_text"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'def classify_text(text: str,\n                  choices: Dict[str, str],\n                  default_response: str = "null",\n                  openai_client: Optional[OpenAI] = None,\n                  openai_api: Optional[str] = None,\n                  temperature: float = 0,\n                  model="gpt-4o-mini") -> str\n'})}),"\n",(0,t.jsx)(s.p,{children:"Given a text, classify it into one of the provided choices with the assistance of a large language model."}),"\n",(0,t.jsx)(s.h4,{id:"arguments-4",children:"Arguments"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"text"})," ",(0,t.jsx)(s.em,{children:"str"})," - The text to classify"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"choices"})," ",(0,t.jsx)(s.em,{children:"Dict[str,str]"})," - A list of choices to classify the text into, with the key being the choice name and the value being a description of the choice"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"default_response"})," ",(0,t.jsx)(s.em,{children:"str"}),' - The default response to return if the text cannot be classified. Defaults to "null".']}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"openai_client"})," ",(0,t.jsx)(s.em,{children:"Optional[OpenAI]"})," - An OpenAI client object, optional. If omitted, will fall back to creating a new OpenAI client with the API key provided as an environment variable"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"openai_api"})," ",(0,t.jsx)(s.em,{children:"Optional[str]"})," - the API key for an OpenAI client, optional. If provided, a new OpenAI client will be created."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"temperature"})," ",(0,t.jsx)(s.em,{children:"float"})," - The temperature to use for GPT. Defaults to 0."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"model"})," ",(0,t.jsx)(s.em,{children:"str"})," - The model to use for the GPT API"]}),"\n"]}),"\n",(0,t.jsx)(s.h4,{id:"returns-4",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"The classification of the text."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.synthesize_user_responses"}),"\n",(0,t.jsx)(s.h3,{id:"synthesize_user_responses",children:"synthesize_user_responses"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'def synthesize_user_responses(messages: List[Dict[str, str]],\n                              custom_instructions: Optional[str] = "",\n                              openai_client: Optional[OpenAI] = None,\n                              openai_api: Optional[str] = None,\n                              temperature: float = 0,\n                              model: str = "gpt-4o-mini") -> str\n'})}),"\n",(0,t.jsx)(s.p,{children:"Given a first draft and a series of follow-up questions and answers, use an LLM to synthesize the user's responses\ninto a single, coherent reply."}),"\n",(0,t.jsx)(s.h4,{id:"arguments-5",children:"Arguments"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"messages"})," ",(0,t.jsx)(s.em,{children:"List[Dict[str, str]]"})," - A list of questions from the LLM and responses from the user"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"custom_instructions"})," ",(0,t.jsx)(s.em,{children:"str"})," - Custom instructions for the LLM to follow in constructing the synthesized response"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"openai_client"})," ",(0,t.jsx)(s.em,{children:"Optional[OpenAI]"})," - An OpenAI client object, optional. If omitted, will fall back to creating a new OpenAI client with the API key provided as an environment variable"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"openai_api"})," ",(0,t.jsx)(s.em,{children:"Optional[str]"})," - the API key for an OpenAI client, optional. If provided, a new OpenAI client will be created."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"temperature"})," ",(0,t.jsx)(s.em,{children:"float"})," - The temperature to use for GPT. Defaults to 0."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"model"})," ",(0,t.jsx)(s.em,{children:"str"})," - The model to use for the GPT API"]}),"\n"]}),"\n",(0,t.jsx)(s.h4,{id:"returns-5",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"A synthesized response from the user."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.define_fields_from_dict"}),"\n",(0,t.jsx)(s.h3,{id:"define_fields_from_dict",children:"define_fields_from_dict"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"def define_fields_from_dict(field_dict: Dict[str, Any],\n                            fields_to_ignore: Optional[List] = None) -> None\n"})}),"\n",(0,t.jsx)(s.p,{children:"Assign values from a dictionary to corresponding Docassemble interview fields."}),"\n",(0,t.jsx)(s.p,{children:"Docassemble and built-in keywords are never defined by this function. If\nfields_to_ignore is provided, those fields will also be ignored."}),"\n",(0,t.jsx)(s.h4,{id:"arguments-6",children:"Arguments"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"field_dict"})," ",(0,t.jsx)(s.em,{children:"Dict[str, Any]"})," - A dictionary of fields to define, with the key\nbeing the field name and the value presumably taken from the output of\nextract_fields_from_text."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"fields_to_ignore"})," ",(0,t.jsx)(s.em,{children:"Optional[List]"}),' - A list of fields to ignore. Defaults to\nNone. Should be used to ensure safety when defining fields from untrusted\nsources. E.g., ["user_is_logged_in"]']}),"\n"]}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.Goal"}),"\n",(0,t.jsx)(s.h2,{id:"goal-objects",children:"Goal Objects"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"class Goal(DAObject)\n"})}),"\n",(0,t.jsx)(s.p,{children:"A class to represent a goal."}),"\n",(0,t.jsx)(s.h4,{id:"attributes",children:"Attributes"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"name"})," ",(0,t.jsx)(s.em,{children:"str"})," - The name of the goal"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"description"})," ",(0,t.jsx)(s.em,{children:"str"})," - A description of the goal"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"satisfied"})," ",(0,t.jsx)(s.em,{children:"bool"})," - Whether the goal is satisfied"]}),"\n"]}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.Goal.response_satisfies_me_or_follow_up"}),"\n",(0,t.jsx)(s.h3,{id:"response_satisfies_me_or_follow_up",children:"response_satisfies_me_or_follow_up"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'def response_satisfies_me_or_follow_up(\n        messages: List[Dict[str, str]],\n        openai_client: Optional[OpenAI] = None,\n        model="gpt-4o-mini",\n        system_message: Optional[str] = None,\n        llm_assumed_role: Optional[str] = "teacher",\n        user_assumed_role: Optional[str] = "student") -> str\n'})}),"\n",(0,t.jsx)(s.p,{children:'Returns the text of the next question to ask the user or the string "satisfied"\nif the user\'s response satisfies the goal.'}),"\n",(0,t.jsx)(s.h4,{id:"arguments-7",children:"Arguments"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"messages"})," ",(0,t.jsx)(s.em,{children:"List[Dict[str, str]]"})," - The messages to check"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"openai_client"})," ",(0,t.jsx)(s.em,{children:"Optional[OpenAI]"})," - An OpenAI client object. Defaults to None."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"model"})," ",(0,t.jsx)(s.em,{children:"str"}),' - The model to use for the OpenAI API. Defaults to "gpt-4o-mini".']}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"system_message"})," ",(0,t.jsx)(s.em,{children:"Optional[str]"})," - The system message to use for the OpenAI API. Defaults to None."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"llm_assumed_role"})," ",(0,t.jsx)(s.em,{children:"Optional[str]"}),' - The role for the LLM to assume. Defaults to "teacher".']}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"user_assumed_role"})," ",(0,t.jsx)(s.em,{children:"Optional[str]"}),' - The role for the user to assume. Defaults to "student".']}),"\n"]}),"\n",(0,t.jsx)(s.h4,{id:"returns-6",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:'The text of the next question to ask the user or the string "satisfied"'}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.Goal.get_next_question"}),"\n",(0,t.jsx)(s.h3,{id:"get_next_question",children:"get_next_question"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'def get_next_question(thread_so_far: List[Dict[str, str]],\n                      openai_client: Optional[OpenAI] = None,\n                      model="gpt-4o-mini") -> str\n'})}),"\n",(0,t.jsx)(s.p,{children:"Returns the text of the next question to ask the user."}),"\n",(0,t.jsx)(s.h4,{id:"arguments-8",children:"Arguments"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"thread_so_far"})," ",(0,t.jsx)(s.em,{children:"List[Dict[str, str]]"})," - The thread of the conversation so far"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"openai_client"})," ",(0,t.jsx)(s.em,{children:"Optional[OpenAI]"})," - An OpenAI client object. Defaults to None."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"model"})," ",(0,t.jsx)(s.em,{children:"str"}),' - The model to use for the OpenAI API. Defaults to "gpt-4o-mini".']}),"\n"]}),"\n",(0,t.jsx)(s.h4,{id:"returns-7",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"The text of the next question to ask the user."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalDict"}),"\n",(0,t.jsx)(s.h2,{id:"goaldict-objects",children:"GoalDict Objects"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"class GoalDict(DADict)\n"})}),"\n",(0,t.jsx)(s.p,{children:"A class to represent a DADict of Goals."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalDict.satisfied"}),"\n",(0,t.jsx)(s.h3,{id:"satisfied",children:"satisfied"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"def satisfied() -> bool\n"})}),"\n",(0,t.jsx)(s.p,{children:"Returns True if all goals are satisfied, False otherwise."}),"\n",(0,t.jsx)(s.h4,{id:"returns-8",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"True if all goals are satisfied, False otherwise."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalQuestion"}),"\n",(0,t.jsx)(s.h2,{id:"goalquestion-objects",children:"GoalQuestion Objects"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"class GoalQuestion(DAObject)\n"})}),"\n",(0,t.jsx)(s.p,{children:"A class to represent a question about a goal."}),"\n",(0,t.jsx)(s.h4,{id:"attributes-1",children:"Attributes"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"goal"})," ",(0,t.jsx)(s.em,{children:"Goal"})," - The goal the question is about"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"question"})," ",(0,t.jsx)(s.em,{children:"str"})," - The question to ask the user"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"response"})," ",(0,t.jsx)(s.em,{children:"str"})," - The user's response to the question"]}),"\n"]}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalQuestion.complete"}),"\n",(0,t.jsx)(s.h3,{id:"complete",children:"complete"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"@property\ndef complete()\n"})}),"\n",(0,t.jsx)(s.p,{children:"Returns True if the goal, question, and response attributes are present."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalSatisfactionList"}),"\n",(0,t.jsx)(s.h2,{id:"goalsatisfactionlist-objects",children:"GoalSatisfactionList Objects"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"class GoalSatisfactionList(DAList)\n"})}),"\n",(0,t.jsx)(s.p,{children:"A class to help ask the user questions until all goals are satisfied."}),"\n",(0,t.jsx)(s.p,{children:"Uses an LLM to prompt the user with follow-up questions if the initial response isn't complete.\nBy default, the number of follow-up questions is limited to 10."}),"\n",(0,t.jsx)(s.p,{children:"This can consume a lot of tokens, as each follow-up has a chance to send the whole conversation\nthread to the LLM."}),"\n",(0,t.jsx)(s.p,{children:"By default, this will use the OpenAI API key defined in the global configuration under this path:"}),"\n",(0,t.jsxs)(s.p,{children:["You can specify the path to an alternative configuration by setting the ",(0,t.jsx)(s.code,{children:"openai_configuration_path"})," attribute."]}),"\n",(0,t.jsx)(s.p,{children:"This object does NOT accept the key as a direct parameter, as that will be leaked in the user's answers."}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{children:"open ai:\n    key: sk-...\n"})}),"\n",(0,t.jsx)(s.h4,{id:"attributes-2",children:"Attributes"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"goals"})," ",(0,t.jsx)(s.em,{children:"List[Goal]"})," - The goals in the list, provided as a dictionary"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"goal_list"})," ",(0,t.jsx)(s.em,{children:"GoalList"})," - The list of Goals"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"question_limit"})," ",(0,t.jsx)(s.em,{children:"int"})," - The maximum number of follow-up questions to ask the user"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"question_per_goal_limit"})," ",(0,t.jsx)(s.em,{children:"int"})," - The maximum number of follow-up questions to ask the user per goal"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"initial_draft"})," ",(0,t.jsx)(s.em,{children:"str"})," - The initial draft of the user's response"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"initial_question"})," ",(0,t.jsx)(s.em,{children:"str"})," - The original question posed in the interview"]}),"\n"]}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalSatisfactionList.mark_satisfied_goals"}),"\n",(0,t.jsx)(s.h3,{id:"mark_satisfied_goals",children:"mark_satisfied_goals"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"def mark_satisfied_goals() -> None\n"})}),"\n",(0,t.jsx)(s.p,{children:"Marks goals as satisfied if the user's response satisfies the goal.\nThis should be used as soon as the user gives their initial reply."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalSatisfactionList.keep_going"}),"\n",(0,t.jsx)(s.h3,{id:"keep_going",children:"keep_going"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"def keep_going() -> bool\n"})}),"\n",(0,t.jsx)(s.p,{children:"Returns True if there is at least one unsatisfied goal and if the number of follow-up questions asked is less than the question limit, False otherwise."}),"\n",(0,t.jsx)(s.h4,{id:"returns-9",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"True if there is at least one unsatisfied goal and if the number of follow-up questions asked is less than the question limit, False otherwise."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalSatisfactionList.need_more_questions"}),"\n",(0,t.jsx)(s.h3,{id:"need_more_questions",children:"need_more_questions"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"def need_more_questions() -> bool\n"})}),"\n",(0,t.jsx)(s.p,{children:"Returns True if there is at least one unsatisfied goal, False otherwise."}),"\n",(0,t.jsx)(s.p,{children:"Also has the side effect of checking the user's most recent response to see if it satisfies the goal\nand updating the next question to be asked."}),"\n",(0,t.jsx)(s.h4,{id:"returns-10",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"True if there is at least one unsatisfied goal, False otherwise."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalSatisfactionList.satisfied"}),"\n",(0,t.jsx)(s.h3,{id:"satisfied-1",children:"satisfied"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"def satisfied() -> bool\n"})}),"\n",(0,t.jsx)(s.p,{children:"Returns True if all goals are satisfied, False otherwise."}),"\n",(0,t.jsx)(s.h4,{id:"returns-11",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"True if all goals are satisfied, False otherwise."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalSatisfactionList.get_next_goal_and_question"}),"\n",(0,t.jsx)(s.h3,{id:"get_next_goal_and_question",children:"get_next_goal_and_question"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"def get_next_goal_and_question() -> tuple\n"})}),"\n",(0,t.jsx)(s.p,{children:"Returns the next unsatisfied goal, along with a follow-up question to ask the user, if relevant."}),"\n",(0,t.jsx)(s.h4,{id:"returns-12",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"A tuple of (Goal, str) where the first item is the next unsatisfied goal and the second item is the next question to ask the user, if relevant.\nIf the user's response to the last question satisfied the goal, returns (None, None)."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalSatisfactionList.synthesize_draft_response"}),"\n",(0,t.jsx)(s.h3,{id:"synthesize_draft_response",children:"synthesize_draft_response"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"def synthesize_draft_response() -> str\n"})}),"\n",(0,t.jsx)(s.p,{children:"Returns a draft response that synthesizes the user's responses to the questions."}),"\n",(0,t.jsx)(s.h4,{id:"returns-13",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"A draft response that synthesizes the user's responses to the questions."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalSatisfactionList.provide_feedback"}),"\n",(0,t.jsx)(s.h3,{id:"provide_feedback",children:"provide_feedback"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'def provide_feedback(\n        feedback_prompt: str = "") -> Union[List[Any], Dict[str, Any], str]\n'})}),"\n",(0,t.jsx)(s.p,{children:"Returns feedback to the user based on the goals they satisfied."}),"\n",(0,t.jsx)(s.h4,{id:"arguments-9",children:"Arguments"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"feedback_prompt"})," ",(0,t.jsx)(s.em,{children:"str"}),' - The prompt to use for the feedback. Defaults to "".']}),"\n"]}),"\n",(0,t.jsx)(s.h4,{id:"returns-14",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"Feedback to the user based on the goals they satisfied."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalOrientedQuestion"}),"\n",(0,t.jsx)(s.h2,{id:"goalorientedquestion-objects",children:"GoalOrientedQuestion Objects"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"class GoalOrientedQuestion(DAObject)\n"})}),"\n",(0,t.jsx)(s.p,{children:"A class to represent a question in a goal-oriented questionnaire."}),"\n",(0,t.jsx)(s.h4,{id:"attributes-3",children:"Attributes"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"question"})," ",(0,t.jsx)(s.em,{children:"str or dict"})," - The question to ask the user (text or field structure)"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"response"})," ",(0,t.jsx)(s.em,{children:"str or dict"})," - The user's response to the question (text or field values)"]}),"\n"]}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalOrientedQuestion.complete"}),"\n",(0,t.jsx)(s.h3,{id:"complete-1",children:"complete"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"@property\ndef complete()\n"})}),"\n",(0,t.jsx)(s.p,{children:"Returns True if the question and response attributes are present."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalOrientedQuestion.response_as_text"}),"\n",(0,t.jsx)(s.h3,{id:"response_as_text",children:"response_as_text"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"def response_as_text() -> str\n"})}),"\n",(0,t.jsx)(s.p,{children:"Returns the response in a readable text format for the LLM."}),"\n",(0,t.jsx)(s.p,{children:"Combines both structured responses from response_dict and the open-ended response.\nUses original labels from the question for better context.\nHandles checkboxes specially by using .true_values() to show only checked items."}),"\n",(0,t.jsx)(s.h4,{id:"returns-15",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"A formatted string representation of all responses."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalOrientedQuestion.build_field_list"}),"\n",(0,t.jsx)(s.h3,{id:"build_field_list",children:"build_field_list"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"def build_field_list() -> List[Dict[str, Any]]\n"})}),"\n",(0,t.jsx)(s.p,{children:"Build a field list from this question object for use in docassemble fields."}),"\n",(0,t.jsx)(s.h4,{id:"returns-16",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"A list of field dictionaries suitable for use in a fields: code: block"}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalOrientedQuestionList"}),"\n",(0,t.jsx)(s.h2,{id:"goalorientedquestionlist-objects",children:"GoalOrientedQuestionList Objects"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"class GoalOrientedQuestionList(DAList)\n"})}),"\n",(0,t.jsx)(s.p,{children:"A class to help ask the user follow-up questions until their response satisfies a single rubric."}),"\n",(0,t.jsx)(s.p,{children:"Unlike GoalSatisfactionList which tracks multiple individual goals, this class focuses on a single\nrubric that describes what constitutes a complete response. The AI will continue asking follow-up\nquestions until the response satisfies the rubric or the question limit is reached."}),"\n",(0,t.jsx)(s.p,{children:"This can consume a lot of tokens, as each follow-up has a chance to send the whole conversation\nthread to the LLM."}),"\n",(0,t.jsx)(s.p,{children:"By default, this will use the OpenAI API key defined in the global configuration under this path:"}),"\n",(0,t.jsxs)(s.p,{children:["You can specify the path to an alternative configuration by setting the ",(0,t.jsx)(s.code,{children:"openai_configuration_path"})," attribute."]}),"\n",(0,t.jsx)(s.p,{children:"This object does NOT accept the key as a direct parameter, as that will be leaked in the user's answers."}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{children:"open ai:\n    key: sk-...\n"})}),"\n",(0,t.jsx)(s.h4,{id:"attributes-4",children:"Attributes"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"rubric"})," ",(0,t.jsx)(s.em,{children:"str"})," - The rubric that describes what constitutes a complete response"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"question_limit"})," ",(0,t.jsx)(s.em,{children:"int"})," - The maximum number of follow-up questions to ask the user. Defaults to 6."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"initial_draft"})," ",(0,t.jsx)(s.em,{children:"str, optional"})," - The initial draft of the user's response (for open-ended initial questions)"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"initial_draft_dict"})," ",(0,t.jsx)(s.em,{children:"DADict, optional"})," - Dictionary of structured responses (for structured initial questions)"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"initial_draft_response"})," ",(0,t.jsx)(s.em,{children:"str, optional"})," - Open-ended response for structured initial questions"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"initial_question"})," ",(0,t.jsx)(s.em,{children:"str"})," - The original question posed in the interview"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"use_structured_initial_question"})," ",(0,t.jsx)(s.em,{children:"bool"})," - If True, generate structured fields for initial question. Defaults to False."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"model"})," ",(0,t.jsx)(s.em,{children:"str"}),' - The model to use for the OpenAI API. Defaults to "gpt-5-nano".']}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"llm_assumed_role"})," ",(0,t.jsx)(s.em,{children:"str"}),' - The role for the LLM to assume. Defaults to "legal aid intake worker".']}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"user_assumed_role"})," ",(0,t.jsx)(s.em,{children:"str"}),' - The role for the user to assume. Defaults to "applicant for legal help".']}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"skip_moderation"})," ",(0,t.jsx)(s.em,{children:"bool"})," - If True, skips moderation checks when generating structured fields. Defaults to True."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"reasoning_effort"})," ",(0,t.jsx)(s.em,{children:'Optional[Literal["minimal", "low", "medium", "high"]]'}),' - The level of reasoning effort to use when generating responses. Defaults to "low"; use "minimal" for increased speed.']}),"\n"]}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalOrientedQuestionList.generate_initial_question_fields"}),"\n",(0,t.jsx)(s.h3,{id:"generate_initial_question_fields",children:"generate_initial_question_fields"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"def generate_initial_question_fields() -> Dict[str, Any]\n"})}),"\n",(0,t.jsx)(s.p,{children:"Generate structured fields for the initial question using the LLM."}),"\n",(0,t.jsx)(s.p,{children:"This allows the initial question to use structured fields (radio, checkboxes, etc.)\ninstead of requiring an open-ended narrative response."}),"\n",(0,t.jsx)(s.h4,{id:"returns-17",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"A dict with the structure for the initial question fields."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalOrientedQuestionList.build_initial_field_list"}),"\n",(0,t.jsx)(s.h3,{id:"build_initial_field_list",children:"build_initial_field_list"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"def build_initial_field_list() -> List[Dict[str, Any]]\n"})}),"\n",(0,t.jsx)(s.p,{children:"Build field list for the initial question when using structured format."}),"\n",(0,t.jsx)(s.h4,{id:"returns-18",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"A list of field dictionaries suitable for use in a fields: code: block"}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalOrientedQuestionList.initial_response_as_text"}),"\n",(0,t.jsx)(s.h3,{id:"initial_response_as_text",children:"initial_response_as_text"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"def initial_response_as_text() -> str\n"})}),"\n",(0,t.jsx)(s.p,{children:"Returns the initial response in text format, handling both string and dict formats."}),"\n",(0,t.jsx)(s.p,{children:"Handles checkboxes specially by using .true_values() to show only checked items."}),"\n",(0,t.jsx)(s.h4,{id:"returns-19",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"A formatted string representation of the initial response."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalOrientedQuestionList.keep_going"}),"\n",(0,t.jsx)(s.h3,{id:"keep_going-1",children:"keep_going"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"def keep_going() -> bool\n"})}),"\n",(0,t.jsx)(s.p,{children:"Returns True if the response is not yet complete and the question limit hasn't been reached."}),"\n",(0,t.jsx)(s.h4,{id:"returns-20",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"True if more questions can be asked, False otherwise."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalOrientedQuestionList.need_more_questions"}),"\n",(0,t.jsx)(s.h3,{id:"need_more_questions-1",children:"need_more_questions"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"def need_more_questions() -> bool\n"})}),"\n",(0,t.jsx)(s.p,{children:"Returns True if the user needs to answer more questions, False otherwise."}),"\n",(0,t.jsx)(s.p,{children:"Also has the side effect of checking the user's most recent response to see if it satisfies\nthe rubric and updating the next question to be asked."}),"\n",(0,t.jsx)(s.h4,{id:"returns-21",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"True if more questions are needed, False otherwise."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalOrientedQuestionList.satisfied"}),"\n",(0,t.jsx)(s.h3,{id:"satisfied-2",children:"satisfied"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"def satisfied() -> bool\n"})}),"\n",(0,t.jsx)(s.p,{children:"Returns True if the rubric is satisfied, False otherwise."}),"\n",(0,t.jsx)(s.h4,{id:"returns-22",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"True if the rubric is satisfied, False otherwise."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalOrientedQuestionList.get_next_question"}),"\n",(0,t.jsx)(s.h3,{id:"get_next_question-1",children:"get_next_question"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"def get_next_question() -> Optional[Union[str, Dict[str, Any]]]\n"})}),"\n",(0,t.jsx)(s.p,{children:"Returns the text or field structure of the next question to ask the user."}),"\n",(0,t.jsx)(s.h4,{id:"returns-23",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"The text/fields of the next question, or None if no more questions are needed."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalOrientedQuestionList.synthesize_draft_response"}),"\n",(0,t.jsx)(s.h3,{id:"synthesize_draft_response-1",children:"synthesize_draft_response"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"def synthesize_draft_response() -> str\n"})}),"\n",(0,t.jsx)(s.p,{children:"Returns a draft response that synthesizes the user's responses to the questions."}),"\n",(0,t.jsx)(s.h4,{id:"returns-24",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"A draft response that synthesizes the user's responses to the questions."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.GoalOrientedQuestionList.provide_feedback"}),"\n",(0,t.jsx)(s.h3,{id:"provide_feedback-1",children:"provide_feedback"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'def provide_feedback(\n        feedback_prompt: str = "") -> Union[List[Any], Dict[str, Any], str]\n'})}),"\n",(0,t.jsx)(s.p,{children:"Returns feedback to the user based on how well they satisfied the rubric."}),"\n",(0,t.jsx)(s.h4,{id:"arguments-10",children:"Arguments"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"feedback_prompt"})," ",(0,t.jsx)(s.em,{children:"str"}),' - The prompt to use for the feedback. Defaults to "".']}),"\n"]}),"\n",(0,t.jsx)(s.h4,{id:"returns-25",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"Feedback to the user based on how well they satisfied the rubric."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.IntakeQuestion"}),"\n",(0,t.jsx)(s.h2,{id:"intakequestion-objects",children:"IntakeQuestion Objects"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"class IntakeQuestion(DAObject)\n"})}),"\n",(0,t.jsx)(s.p,{children:"A class to represent a question in an LLM-assisted intake questionnaire."}),"\n",(0,t.jsx)(s.h4,{id:"attributes-5",children:"Attributes"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"question"})," ",(0,t.jsx)(s.em,{children:"str"})," - The question to ask the user"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"response"})," ",(0,t.jsx)(s.em,{children:"str"})," - The user's response to the question"]}),"\n"]}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.IntakeQuestion.complete"}),"\n",(0,t.jsx)(s.h3,{id:"complete-2",children:"complete"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"@property\ndef complete()\n"})}),"\n",(0,t.jsx)(s.p,{children:"Returns True if the question and response attributes are present."}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.IntakeQuestionList"}),"\n",(0,t.jsx)(s.h2,{id:"intakequestionlist-objects",children:"IntakeQuestionList Objects"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"class IntakeQuestionList(DAList)\n"})}),"\n",(0,t.jsx)(s.p,{children:"Class to help create an LLM-assisted intake questionnaire."}),"\n",(0,t.jsx)(s.p,{children:"The LLM will be provided a free-form set of in/out criteria (like that\nprovided to a phone intake worker), an initial draft question from the user,\nand then guide the user through a series of follow-up questions to gather only\nenough information to determine if the user meets the criteria."}),"\n",(0,t.jsx)(s.p,{children:"In/out criteria are often pretty short, so we do not make or support\nembeddings at the moment."}),"\n",(0,t.jsx)(s.h4,{id:"attributes-6",children:"Attributes"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"criteria"})," ",(0,t.jsx)(s.em,{children:"Dict[str, str]"})," - A dictionary of criteria to match, indexed by problem type"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"problem_type_descriptions"})," ",(0,t.jsx)(s.em,{children:"Dict[str, str]"})," - A dictionary of descriptions of the problem types"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"problem_type"})," ",(0,t.jsx)(s.em,{children:"str"})," - The type of problem to match. E.g., a unit/department inside the law firm"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"initial_problem_description"})," ",(0,t.jsx)(s.em,{children:"str"})," - The initial description of the problem from the user"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"initial_question"})," ",(0,t.jsx)(s.em,{children:"str"})," - The original question posed in the interview"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"question_limit"})," ",(0,t.jsx)(s.em,{children:"int"})," - The maximum number of follow-up questions to ask the user. Defaults to 10."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"model"})," ",(0,t.jsx)(s.em,{children:"str"})," - The model to use for the GPT API. Defaults to gpt-4.1."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"max_output_tokens"})," ",(0,t.jsx)(s.em,{children:"int"})," - The maximum number of tokens to return from the API. Defaults to 4096"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"llm_role"})," ",(0,t.jsx)(s.em,{children:"str"})," - The role the LLM should play. Allows you to customize the script the LLM uses to guide the user.\nWe have provided a default script that should work for most intake questionnaires."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"llm_user_qualifies_prompt"})," ",(0,t.jsx)(s.em,{children:"str"})," - The prompt to use to determine if the user qualifies. We have provided a default prompt."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"out_of_questions"})," ",(0,t.jsx)(s.em,{children:"bool"})," - Whether the user has run out of questions to answer"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"qualifies"})," ",(0,t.jsx)(s.em,{children:"bool"})," - Whether the user qualifies based on the criteria"]}),"\n"]}),"\n",(0,t.jsx)("a",{id:"ALToolbox.llms.IntakeQuestionList.need_more_questions"}),"\n",(0,t.jsx)(s.h3,{id:"need_more_questions-2",children:"need_more_questions"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"def need_more_questions() -> bool\n"})}),"\n",(0,t.jsx)(s.p,{children:"Returns True if the user needs to answer more questions, False otherwise."}),"\n",(0,t.jsx)(s.p,{children:"Also has the side effect of checking the user's most recent response to see if it satisfies the criteria\nand updating both the next question to be asked and the current qualification status."}),"\n",(0,t.jsx)(s.h4,{id:"returns-26",children:"Returns"}),"\n",(0,t.jsx)(s.p,{children:"True if the user needs to answer more questions, False otherwise."})]})}function h(e={}){const{wrapper:s}={...(0,l.R)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}}}]);